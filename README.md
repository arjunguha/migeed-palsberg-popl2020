

# What is Decidable about Gradual Types?
This artifact is for our POPL 2020 submission.

------------

### Step 0: VM
You can download a copy of our VM which has all the requirements installed, as well as the required code. 

### Step 1: Dependencies

Another option is to install the dependencies by following these steps (these steps are for Ubuntu):

------------
 - Go to the terminal and run `sudo apt-get install haskell-platform`
 - Then install stack by running `curl -sSL https://get.haskellstack.org/ | sh`
 - Install the test library by running `stack install hspec`
 - Install the performance tool by running `stack install criterion`
 
### Step 2: GitHub repository
 If you did not use the VM, then  Clone this repository:  https://github.com/migeed-z/Maximal-Migration 
This creates a root directory called Maximal-Migration in your current working directory.

### Step 3: Run all the tests
------------
- If you downloaded the VM, open the terminal and run: `cd Maximal-Migration`
- If you downloaded the repo, then go to the root directory.
- Run `stack build`
- Run `stack test/Test.hs`

This will run all algorithms on the examples mentioned in the paper so we can verify their correctness. Performance will be evaluated using another command. One general note about these tests is that the symbol * in the artifact stands for `dyn`. So `λx : * . x (succ x)` is the same as `λx : dyn . x (succ x)` and also the same as `λx . x (succ x)`  (because * stands for the unknown type). 
Throughout the artifact, we use first representation only, but the other two representations appear in the paper. We will verify the results in figures 4,5,6 and 7 as well as two examples mentioned in section 7.

### Step 4: Verify Figure 4
First, we want to verify the results which appear in Figure 4 in the paper. The figure summarizes four kinds of checks on 12 benchmarks.

In the terminal, you will now see the output for each of the four checks on the 12 benchmarks in Figure 4, in the order they appear in the paper (except for the last check which we will discuss). Below is some sample output for each check. In all the results below, True corresponds to ✔ and False corresponds to ✕ in figure 4. 

------------
**Singleton check**

    sees that λx : * . x (succ x) is singleton? = True
    sees that λx : * . x (succ (x True)) is singleton? = False
    sees that λx : * . + (x 4) (x True) is singleton? = False

------------
**Top choice check**

     sees that λx : * . x (succ x) has a top choice? =  True
     sees that λx : * . x (succ (x True)) has a top choice? =  True
     sees that λx : * . + (x 4) (x True) has a top choice? =  True

------------

**Finitness check**

      sees that λx : * . x (succ x) is finite? = True
      sees that λx : * . x (succ (x True)) is finite? = True
      sees that λx : * . + (x 4) (x True) is finite? = True

------------
Maximality check is divided into two categories in our artifact. One for small programs (going upto level 5 in the lattice, and one for large programs going up to level 3). We will describe how to change this level in the next step.
You will see this output in the terminal:

**Maximality check (benchmarks 1-10)**
The output below this corresponds to benchmarks 10-12 in Fig 4

**Maximality check (benchmarks 11 &12) & NPHard**
The output consists of 4 benchmarks. The first two are benchmarks 11 and 12 in the figure while the last two are the benchmark E_{f2} from the paper, and the mapping generated from f_8 in section 7. We can see that E_{f2} has a maximal migration and that the mapping from f_8 does not, since f_8 is unsatisfiable.

### Step 5: Verify Figure 6 
We now verify the results in Figure 6. 

In the terminal, we will see text that says: **Show migrations (fig 6)**
 which displays the actual migration for each figure in the table if it exists, and outputs Nothing otherwise. Here is a sample output:

------------


**Show migrations (fig 6) benchmarks 1-10**

    sees that λx : * . x (succ x) has a maximal migration Just (λx : * . x (succ x))
    sees that λx : * . x x has a maximal migration Nothing


This check has the first 10 benchmarks where we explore the lattice upto level 5.
If a migration exists, it will be wrapped in a *Just* constructor. If no migration exists, the output will be *Nothing*.

------------

**Show migrations (fig 6) 11,12 and f_8**

     sees that (λx : * . λy : * . y (x (λa : * . a)) (x (λb : * . λc : * . b))) (λd : * . d d) has a maximal migration Nothing

Next, the above check will run benchmarks 11 and 12, as well as the program generated by $f_8$ upto level 3 of the lattice.

------------

Finally, you will notice that for the program

    λx : * . λy : * . y x x, 

the maximal migration given by the tool  is 

    λx : * . λy : int -> bool -> int . y x x

This is because the function we use in this test finds the *closest* maximal in the lattice. To see that the migration in the table is indeed a valid migration, you can see the next check:

**find specific maximal migration**

    sees that λx : int . λy : int -> int -> int . y x x is a maximal migration for λx : * . λy : * . y x x



Here, we run the migration algorithm upto level 5 and collect all maximal migrations and check that the migration shown in the table is valid.


------------

### Step 6: NP Hardness examples
We want to verify that the NP hardness example seen in section 6.3 has a maximal migration. 

For this, read the part of the output which says:

**NP hard example**
Below that line, you will see the proram and the corresponding maximal migration. For this, we have implemented a mapping function *make_mapping* in `NPHard.hs` which takes boolean formulas to programs.  A check is called on that program to verify that it is indeed a maximal migration.

### Step 7: Exploring the lattice
To run the maximality algorithm upto a given level in the lattice, uncomment the line of code that says 
`    -- test_mult_migrate` in `test/Test.hs` then rerun the command:
` stack test/Test.hs`

In Test.hs, go to the line of code that says `test_mult_migrate :: Spec`
where you will see a sample test:
`    example 3 lam [lam1, lam2]
`
This means, run the program lam upto level 3 of the lattice and output the maximal migrations. [lam1, lam2] are the maximal migrations for this program. 

When you run this test, the following output will be displayed:

      sees that at level 3 λx : * . (λy : * . x) x x has migrations [λx : * . (λy : int . x) x x,λx : * . (λy : bool . x) x x]

Sample programs to run tests on can be found in` src/Examples.hs `. 

### Step 8: Verify Figure 7
You will see the check:
**Typecheck (fig 7)**
This will list all maximal benchmarks and their corresponding types. Figure 7 lists the programs *before* migration, and the types *after* migration. However, we have already verified that we find the maximal migrations correctly, so it remains to check that the types of those migrations correspond to those in figure 7,


### Step 9: Verify Figure 5

To run the performance tests in Figure 5, run the command:

`stack test/Performance.hs `

You can also generate an html report with 
regression tests and time density tests for each benchmark and each check by running the command  

`stack test/Performance.hs --output Report.html`

In both cases, the following will be displayed on the screen:

    > benchmarking Singleton /1
    time                 319.9 ns   (317.3 ns .. 323.6 ns)
                         0.999 R²   (0.999 R² .. 0.999 R²)
    mean                 327.4 ns   (324.7 ns .. 330.1 ns)
    std dev              9.265 ns   (7.906 ns .. 10.93 ns)
    variance introduced by outliers: 41% (moderately inflated)

The above output  means we are running the Singleton check on the benchmark 1. We can see the mean, std dev. and other statistics. Our 12 benchmarks are marked 1 to 12 in the order they appear in Figure 4. We also have the two additional benchmarks from section 7. The SAT example is benchmark 13, and the program generated from f_8 is benchmark 14. Singleton, Finiteness and TopChoice run on the base 12 benchmarks and Maximality runs on all 14 benchmarks.

Performance tests are separated into groups. Let us identify these groups.
- Singleton
Runs all singleton checks on our 12 benchmarks

- Finiteness
Runs finiteness checks on the 9 (smaller) benchmarks 1-8 and 10

- FLarge
Runs finiteness checks on the 3 (large) benchmarks 9, 11 and 12

- TopChoice
Runs topchoice checks on the first 9 (smaller) benchmarks 

- TCLarge
Runs topchoice checks on the last 3 (large) benchmarks 

- Maximality
Runs maximality checks on the first 9 (smaller) benchmarks upto level 5 of the lattice 

- MLarge
Runs maximality checks on the last 3 (larger) benchmarks upto level 3 of the lattice

- MappingSAT
Measures the maximality check on the NPhardness SAT program (benchmark 13)

- MappingUNSAT
Measures the maximality check on the NPhardness UNSAT program (benchmark 14)

You can run each group individually to see the performance and generate a separate html report. A report also lets you see how many times each benchmark was run.

To run a separate group, use this command:

`stack test/Performance.hs --output report.html groupName`

Without report:
`stack test/Performance.hs  groupName`

For the group MLarge, we recommend running it for a longer time to ensure that each benchmark runs at least 100 times. For this, use the command

`stack test/Performance.hs --output report.html -L 1000 MLarge`

